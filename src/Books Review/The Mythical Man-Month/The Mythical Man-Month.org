#+SETUPFILE: ~/.emacs.d/src/org-templates/level-2.org
#+TITLE: The Mythical Man-Month Notes
#+OPTIONS: num:nil H:2

* The Tar Pit
** The Programming Systems Product
Moving down across the horizontal boundary, a program
becomes a programming product. This is a program that can be run,tested, repaired, and extended by anybody. It is usable in many
operating environments, for many sets of data. To become a generally
usable programming product, a program must be written in a
generalized fashion. In particular the range and form of inputs
must be generalized as much as the basic algorithm will reasonably
allow. Then the program must be thoroughly tested, so that it can
be depended upon. This means that a substantial bank of test
cases, exploring the input range and probing its boundaries, must
be prepared, run, and recorded. Finally, promotion of a program
to a programming product requires its thorough documentation, so
that anyone may use it, fix it, and extend it. As a rule of thumb,
I estimate that a programming product costs at least three times as
much as a debugged program with the same function.

Moving across the vertical boundary, a program becomes a
component in a programming system. This is a collection of interacting
programs, coordinated in function and disciplined in format,
so that the assemblage constitutes an entire facility for large tasks.
To become a programming system component, a program must be
written so that every input and output conforms in syntax and
semantics with precisely defined interfaces. The program must
also be designed so that it uses only a prescribed budget of resources—
memory space, input-output devices, computer time. Finally,
the program must be tested with other system components,
in all expected combinations. This testing must be extensive, for
the number of cases grows combinatorially. It is time-consuming,
for subtle bugs arise from unexpected interactions of debugged
components. A programming system component costs at least
three times as much as a stand-alone program of the same function.
The cost may be greater if the system has many components.

In the lower right-hand corner of Fig. 1.1 stands the programming
systems product. This differs from the simple program in all of
the above ways. It costs nine times as much. But it is the truly
useful object, the intended product of most system programming
efforts.

** The Joys of the Craft
First is the sheer joy of making things

Second is the pleasure of making things that are useful to
other people.

Third is the fascination of fashioning complex puzzle-like
objects of interlocking moving parts and watching them work in
subtle cycles, playing out the consequences of principles built in
from the beginning.

Fourth is the joy of always learning, which springs from the
nonrepeating nature of the task.

Finally, there is the delight of working in such a tractable
medium.
** The Woes of the Craft
First, one must perform perfectly. The computer resembles the
magic of legend in this respect, too. If one character, one pause, of
the incantation is not strictly in proper form, the magic doesn't
work.

Next, other people set one's objectives, provide one's resources,
and furnish one's information. One rarely controls the
circumstances of his work, or even its goal.

The next woe is that designing grand concepts is fun; finding
nitty little bugs is just work. With any creative activity come dreary hours of tedious, painstaking labor, and programming is no
exception.

Next, one finds that debugging has a linear convergence, or
worse, where one somehow expects a quadratic sort of approach
to the end. So testing drags on and on, the last difficult bugs taking
more time to find than the first.

The last woe, and sometimes the last straw, is that the product
over which one has labored so long appears to be obsolete upon
(or before) completion. Already colleagues and competitors are in
hot pursuit of new and better ideas. Already the displacement of
one's thought-child is not only conceived, but scheduled.

* The Mythical Man-Month
More software projects have gone awry for lack of calendar time
than for all other causes combined. Why is this cause of disaster
so common?

First, our techniques of estimating are poorly developed.

Second, our estimating techniques fallaciously confuse effort
with progress, hiding the assumption that men and months are
interchangeable.

Third, because we are uncertain of our estimates, software
managers often lack the courteous stubbornness of Antoine's chef.

Fourth, schedule progress is poorly monitored.

Fifth, when schedule slippage is recognized, the natural (and
traditional) response is to add manpower.

For some years I have been successfully using the following
rule of thumb for scheduling a software task:
#+begin_verse
l/3 planning
l/6 coding
l/4 component test and early system test
l/4 system test, all components in hand.
#+end_verse

This differs from conventional scheduling in several important
ways:

1. The fraction devoted to planning is larger than normal. Even
so, it is barely enough to produce a detailed and solid specification,
and not enough to include research or exploration of
totally new techniques.

2. The half of the schedule devoted to debugging of completed
code is much larger than normal.

3. The part that is easy to estimate, i.e., coding, is given only
one-sixth of the schedule.

* The Surgical Team
** Mills's Proposal
Mills proposes that each segment of a large job be tackled
by a team, but that the team be organized like a surgical team
rather than a hog-butchering team. That is, instead of each member
cutting away on the problem, one does the cutting and the
others give him every support that will enhance his effectiveness
and productivity.

The surgeon. Mills calls him a chief programmer. He personally
defines the functional and performance specifications, designs the
program, codes it, tests it, and writes its documentation.

The copilot. He is the alter ego of the surgeon, able to do any
part of the job, but is less experienced. His main function is to
share in the design as a thinkerrdiscussant, and evaluator. The
surgeon tries ideas on him, but is not bound by his advice. The
copilot often represents his team in discussions of function and
interface with other teams. He knows all the code intimately. He
researches alternative design strategies. He obviously serves as
insurance against disaster to the surgeon. He may even write code,
but he is not responsible for any part of the code.

The administrator. The surgeon is boss, and he must have the
last word on personnel, raises, space, and so on, but he must spend
almost none of his time on these matters. Thus he needs a professional
administrator who handles money, people, space, and machines,
and who interfaces with the administrative machinery of
the rest of the organization. Baker suggests that the administrator
has a full-time job only if the project has substantial legal, contractual,
reporting, or financial requirements because of the userproducer
relationship. Otherwise, one administrator can serve two
teams.

The editor. The surgeon is responsible for generating the documentation—
for maximum clarity he must write it. This is true of
both external and internal descriptions. The editor, however, takes
the draft or dictated manuscript produced by the surgeon and
criticizes it, reworks it, provides it with references and bibliography,
nurses it through several versions, and oversees the mechanics
of production.

Two secretaries. The administrator and the editor will each need
a secretary; the administrator's secretary will handle project correspondence
and non-product files.

The program clerk. He is responsible for maintaining all the
technical records of the team in a programming-product library.
The clerk is trained as a secretary and has responsibility for both
machine-readable and human-readable files.

The toolsmith. File-editing, text-editing, and interactive debugging
services are now readily available, so that a team will rarely
need its own machine and machine-operating crew. But these
services must be available with unquestionably satisfactory response
and reliability; and the surgeon must be sole judge of the
adequacy of the service available to him. He needs a toolsmith,
responsible for ensuring this adequacy of the basic service and for
constructing, maintaining, and upgrading special tools—mostly
interactive computer services—needed by his team. Each team will
need its own toolsmith, regardless of the excellence and reliability
of any centrally provided service, for his job is to see to the tools
needed or wanted by his surgeon, without regard to any other
team's needs. The tool-builder will often construct specialized
utilities, catalogued procedures, macro libraries.

The tester. The surgeon will need a bank of suitable test cases
for testing pieces of his work as he writes it, and then for testing
the whole thing.

The language lawyer. By the time Algol came along, people
began to recognize that most computer installations have one or
two people who delight in mastery of the intricacies of a programming
language.



** How It Works
Notice in particular the differences between a team of two
programmers conventionally organized and the surgeon-copilot
team. First, in the conventional team the partners divide the work,
and each is responsible for design and implementation of part of
the work. In the surgical team, the surgeon and copilot are each
cognizant of all of the design and all of the code. This saves the
labor of allocating space, disk accesses, etc. It also ensures the
conceptual integrity of the work.

 In the surgical team, there are no
differences of interest, and differences of judgment are settled by
the surgeon unilaterally. These two differences—lack of division
of the problem and the superior-subordinate relationship—make
it possible for the surgical team to act uno animo.

* Aristocracy, Democracy, and System Design
** Conceptual Integrity
I will contend that conceptual integrity is the most important
consideration in system design. It is better to have a system omit
certain anomalous features and improvements, but to reflect one
set of design ideas, than to have one that contains many good but
independent and uncoordinated ideas.

** Achieving Conceptual Integrity
Because ease of use is the purpose, this ratio of function to
conceptual complexity is the ultimate test of system design. Nei-
ther function alone nor simplicity alone defines a good design.

Simplicity and straightfor-
wardness proceed from conceptual integrity. Every part must re-
flect the same philosophies and the same balancing of desiderata.
Every part must even use the same techniques in syntax and
analogous notions in semantics. Ease of use, then, dictates unity
of design, conceptual integrity.

** Aristocracy and Democracy
Conceptual integrity in turn dictates that the design must proceed
from one mind, or from a very small number of agreeing resonant
minds.

Schedule pressures, however, dictate that system building
needs many hands. Two techniques are available for resolving this
dilemma. The first is a careful division of labor between architec-
ture and implementation. The second is the new way of structur-
ing programming implementation teams discussed in the previous
chapter.

The separation of architectural effort from implementation is
a very powerful way of getting conceptual integrity on very large
projects.

By the architecture of a system, I mean the complete and de-
tailed specification of the user interface. For a computer this is the
programming manual. For a compiler it is the language manual. For
a control program it is the manuals for the language or languages
used to invoke its functions. For the entire system it is the union
of the manuals the user must consult to do his entire job.

Architecture must be carefully distinguished from implemen-
tation. As Blaauw has said, "Where architecture tells what hap-
pens, implementation tells how it is made to happen."

** What Does the Implementer Do While Waiting?
The architecture manager had 10 good men. He asserted that
they could write the specifications and do it right.

The control program manager had 150 men. He asserted that
they could prepare the specifications, with the architecture team
coordinating; it would be well-done and practical, and he could do
it on schedule. 

As Blaauw points out, the total creative effort involves three
distinct phases: architecture, implementation, and realization. It
turns out that these can in fact be begun in parallel and proceed
simultaneously.

In computer design, for example, the implementer can start as
soon as he has relatively vague assumptions about the manual,
somewhat clearer ideas about the technology, and well-defined
cost and performance objectives. He can begin designing data
flows, control sequences, gross packaging concepts, and so on. He
devises or adapts the tools he will need, especially the record-
keeping system, including the design automation system.

* The Second-System Effect
** Interactive Discipline for the Architect
The architect has two possible answers when confronted with
an estimate that is too high: cut the design or challenge the esti-
mate by suggesting cheaper implementations. This latter is inher-
ently an emotion-generating activity. The architect is now
challenging the builder's way of doing the builder's job. For it to
be successful, the architect must
• remember that the builder has the inventive and creative re-
sponsibility for the implementation; so the architect suggests,
not dictates;
• always be prepared to suggest a way of implementing any-
thing he specifies, and be prepared to accept any other way
that meets the objectives as well;
• deal quietly and privately in such suggestions;
• be ready to forego credit for suggested improvements.
** Self-Discipline—The Second-System Effect
How does the architect avoid the second-system effect? Well,
obviously he can't skip his second system. But he can be conscious
of the peculiar hazards of that system, and exert extra self-disci-
pline to avoid functional ornamentation and to avoid extrapola-
tion of functions that are obviated by changes in assumptions and
purposes.

A discipline that will open an architect's eyes is to assign each
little function a value: capability x is worth not more than m bytes
of memory and n microseconds per invocation. These values will
guide initial decisions and serve during implementation as a guide
and warning to all.

* Passing the Word
** Written Specifications—the Manual
I think the finest piece of manual writing I have ever seen is
Blaauw's Appendix to System/360 Principles of Operation. This de-
scribes with care and precision the limits of System/360 compati-
bility. It defines compatibility, prescribes what is to be achieved,
and enumerates those areas of external appearance where the ar-
chitecture is intentionally silent and where results from one model
may differ from those of another, where one copy of a given model
may differ from another copy, or where a copy may differ even
from itself after an engineering change. This is the level of preci-
sion to which manual writers aspire, and they must define what
is not prescribed as carefully as what is.
** Formal Definitions
English, or any other human language, is not naturally a precision
instrument for such definitions. Therefore the manual writer must
strain himself and his language to achieve the precision needed.
An attractive alternative is to use a formal notation for such definitions. 

An ancient adage warns, "Never go to sea with two chronom-
eters; take one or three." The same thing clearly applies to prose
and formal definitions. If one has both, one must be the standard,
and the other must be a derivative description, clearly labeled as
such. Either can be the primary standard. Algol 68 has a formal
definition as standard and a prose definition as descriptive. PL/I
has the prose as standard and the formal description as derivative.

Many tools are available for formal definition. The Backus-
Naur Form is familiar for language definition, and it is amply
discussed in the literature.[fn:1] The formal description of PL/I uses
new notions of abstract syntax, and it is adequately described.[fn:2]
Iverson's APL has been used to describe machines, most notably
the IBM 7090[fn:3] and System/360.[fn:4]

Bell and Newell have proposed new notations for describing
both configurations and machine architectures, and they have il-
lustrated these with several machines, including the DEC PDP-8,[fn:5]
the 7090[fn:5], and System/360.[fn:6]

t is an implementation; it
runs. So all questions of definition can be resolved by testing it.

Using an implementation as a definition has some advantages.
All questions can be settled unambiguously by experiment. De-
bate is never needed, so answers are quick. Answers are always as
precise as one wants, and they are always correct, by definition.


The implementation as a definition overprescribed; it not only said what the machine must do, it also said a
great deal about how it had to do it.

Then, too, the implementation will sometimes give unex-
pected and unplanned answers when sharp questions are asked,
and the de facto definition will often be found to be inelegant in
these particulars precisely because they have never received any
thought. 

Finally, the use of an implementation as a formal definition is
peculiarly susceptible to confusion as to whether the prose de-
scription or the formal description is in fact the standard. This is
especially true of programmed simulations.

** Direct Incorporation
It is especially useful
for establishing the syntax, if not the semantics, of intermodule
interfaces. This technique is to design the declaration of the passed
parameters or shared storage, and to require the implementations
to include that declaration via a compile-time operation (a macro
or a % INCLUDE in PL/I). 
** Conferences and Courts
A new problem
is usually discussed a while. The emphasis is on creativity, rather
than merely decision. The group attempts to invent many solu-
tions to problems, then a few solutions are passed to one or more
of the architects for detailing into precisely worded manual change
proposals.

The fruitfulness of these meetings springs from several
sources:
1. The same group—architects, users, and implementers—meets weekly for
   months. No time is needed for bringing people up to date.
2. The group is bright, resourceful, well versed in the issues, and
   deeply involved in the outcome. No one has an "advisory" role. Everyone is authorized to make binding commitments.
3. When problems are raised, solutions are sought both within and outside the obvious boundaries.
4. The formality of written proposals focuses attention, forces decision, and avoids committee-drafted inconsistencies.
5. The clear vesting of decision-making power in the chief architect avoids compromise and delay.

** The Telephone Log
One useful mechanism is a telephone log kept by the architect.
In it he records every question and every answer. Each week the
logs of the several architects are concatenated, reproduced, and
distributed to the users and implementers. While this mechanism
is quite informal, it is both quick and comprehensive.
** Product Test
Time after time, the careful product tester will find
places where the word didn't get passed, where the design deci-
sions were not properly understood or accurately implemented.
For this reason such a testing group is a necessary link in the chain
by which the design word is passed, a link that needs to operate
early and simultaneously with design.

* Why Did the Tower of Babel Fail?
** A Management Audit of the Babel Project
 In two respects—communication, and its con-
sequent, organization. They were unable to talk with each other;
hence they could not coordinate. When coordination failed, work
ground to a halt. Reading between the lines we gather that lack
of communication led to disputes, bad feelings, and group jeal-
ousies. Shortly the clans began to move apart, preferring isolation
to wrangling.
** Communication in the Large Programming Project
How, then, shall teams communicate with one another? In as
many ways as possible.
+ Informally. Good telephone service and a clear definition of
  intergroup dependencies will encourage the hundreds of calls upon
  which common interpretation of written documents depends.
+ Meetings. Regular project meetings, with one team after another
  giving technical briefings, are invaluable. Hundreds of minor misunderstandings get smoked out this way.
+ Workbook. A formal project workbook must be started at the beginning. This deserves a section by itself.

** The Project Workbook
What. All the documents of the project need to be part of this struc-
ture. This includes objectives, external specifications, interface
specifications, technical standards, internal specifications, and ad-
ministrative memoranda.

Why. Technical prose is almost immortal. If one examines the
genealogy of a customer manual for a piece of hardware or soft-
ware, one can trace not only the ideas, but also many of the very
sentences and paragraphs back to the first memoranda proposing
the product or explaining the first design.

it is very important to get the
structure of the documentation right. The early design of the
project workbook ensures that the documentation structure itself
is crafted, not haphazard. Moreover, the establishment of a struc-
ture molds later writing into segments that fit into that structure.

The second reason for the project workbook is control of the
distribution of information.

Mechanics. First, one must
mark changed text on the page, e.g., by a vertical bar in the margin
alongside every altered line. Second, one needs to distribute with
the new pages a short, separately written change summary that
lists the changes and remarks on their significance.

On balance I think the microfiche was a very happy mecha-
nism, and I would recommend it over a paper workbook for very
large projects.

How would one do it today? With today's system technology
available, I think the technique of choice is to keep the workbook
on the direct-access file, marked with change bars and revision
dates. Each user would consult it from a display terminal

** Organization in the Large Programming Project
If there are n workers on a project, there are (n^2-n)/2 interfaces
across which there may be communication, and there are poten-
tially almost 2^n teams within which coordination must occur. The
purpose of organization is to reduce the amount of communication and coordination necessary; hence organization is a radical attack
on the communication problems treated above.

The means by which communication is obviated are division of
labor and specialization of function. The tree-like structure of orga-
nizations reflects the diminishing need for detailed communica-
tion when division and specialization of labor are applied.

Let us consider a tree-like programming organization, and
examine the essentials which any subtree must have in order to be
effective. They are:
1. a mission
2. a producer
3. a technical director or architect
4. a schedule
5. a division of labor
6. interface definitions among the parts

What is the role of the producer? He assembles the team,
divides the work, and establishes the schedule. He acquires and
keeps on acquiring the necessary resources.This means that a
major part of his role is communication outside the team, upwards
and sideways. He establishes the pattern of communication and
reporting within the team. Finally, he ensures that the schedule is
met, shifting resources and organization to respond to changing
circumstances.

How about the technical director? He conceives of the design
to be built, identifies its subparts, specifies how it will look from
outside, and sketches its internal structure. He provides unity and
conceptual integrity to the whole design; thus he serves as a limit
on system complexity. As individual technical problems arise, he
invents solutions for them or shifts the system design as required.

The producer and the technical director may be the same man.
This is readily workable on very small teams, perhaps three to six
programmers. On larger projects it is very rarely workable, for two
reasons. First, the man with strong management talent and strong
technical talent is rarely found. Thinkers are rare; doers are rarer;
and thinker-doers are rarest.

The producer may be boss, the director his right-hand man.

The director may be boss, and the producer his right-hand man.
* Calling the Shot
#+begin_verse
Practice is the best of all instructors.
                             PUBUUUS
Experience is a dear teacher, but fools will learn at no other.
                         POOR RICHARD'S ALMANAC
#+end_vers
How long will a system programming job take? How much effort
will be required? How does one estimate?

First, one must say
that one does not estimate the entire task by estimating the coding
portion only and then applying the ratios. The coding is only
one-sixth or so of the problem, and errors in its estimate or in the
ratios could lead to ridiculous'results.

Second, one must say that data for building isolated small
programs are not applicable to programming systems products.
Planning, documentation, testing, system integration,
and training times must be added. The linear extrapolation of such
sprint figures is meaningless. Extrapolation of times for the hun-
dred-yard dash shows that a man can run a mile in under three
minutes.

Before dismissing them, however, let us note that these num-
bers, although not for strictly comparable problems, suggest that
effort goes as a power of size even when no communication is
involved except that of a man with his memories.

It illustrates results reported from
a study done by Nanus and Farr[fn:7] at System Development Corpo-
ration. This shows an exponent of 1.5; that is,

effort = (constant) X (number of instructions)^1.5.

Another SDC study reported by Weinwurm3 also shows an expo-
nent near 1.5.

Morin has prepared a survey of the published data.[fn:8]

* Ten Pounds in a Five-Pound Sack
** Program Space as Cost
Since size is such a large part of the user cost of a programming
system product, the builder must set size targets, control size, and
devise size-reduction techniques, just as the hardware builder sets
component-count targets, controls component count, and devises
count-reduction techniques. Like any cost, size itself is not bad,
but unnecessary size is.
** Size Control
First, setting size targets for core is not enough; one has to
budget all aspects of size. 

So the second moral is also clear: Define exactly what a
module must do when you specify how big it must be.

A third and deeper lesson shows through these experiences.
All during implementation, the
system architects must maintain continual vigilance to ensure con-
tinued system integrity. Beyond this policing mechanism, how-
ever, lies the matter of attitude of the implementers themselves.
Fostering a total-system, user-oriented attitude may well be the
most important function of the programming manager.

** Space Techniques
Obviously, more function means more space, speed being held
constant. So the first area of craftsmanship is in trading function
for size. One can design
a program with many optional features, each of which takes a little
space. One can design a generator that will take an option Jist and
tailor a program to it. So the designer must decide how fine-grained the user
choice of options will be.

The second area of craftsmanship is space-time trade-offs. For
a given function, the more space, the faster. This is true over an
amazingly large range. It is this fact that makes it feasible to set
space budgets.

The manager can do two things to help his team make good
space-time trade-offs. One is to ensure that they are trained in
programming technique, not just left to rely on native wit and
previous experience.

The second is to recognize that programming has a technol-
ogy, and components need to be fabricated. Every project needs
a notebook full of good subroutines or macros for queuing, search-
ing, hashing, and sorting. For each such function the notebook
should have at least two programs, the quick and the squeezed.

** Representation Is the Essence of Programming
The programmer at wit's end for lack of space can often do
best by disentangling himself from his code, rearing back, and
contemplating his data. Representation is the essence of program-
ming.
* The Documentary Hypothesis
** Documents for a Computer Product
Suppose one is building a machine. What are the critical documents?

+ Objectives. This defines the need to be met and the goals, desiderata, constraints, and priorities.
+ Specifications. This is a computer manual plus performance
  specifications. It is one of the first documents generated in
  propos- ing a new product, and the last document finished.
+ Schedule
+ Budget. Not merely a constraint, the budget is one of the manager's
  most useful documents. Existence of the budget forces technical
  decisions that otherwise would be avoided; and, more important, it forces and clarifies policy decisions.
+ Organization chart
+ Space allocations
+ Estimate, forecast, prices. These three have cyclic Interlocking,
  which determines the success or failure of the project.
** Documents for a University Department
#+begin_verse
Objectives
Course descriptions
Degree requirements
Research proposals (hence plans, when funded)
Class schedule and teaching assignments
Budget
Space allocation
Assignment of staff and graduate students
#+end_verse
** Documents for a Software Project
+ What: objectives. This defines the need to be met and the goals, desiderata, constraints, and priorities.
+ What: product specifications. This begins as a proposal and ends up
  as the manual and internal documentation. Speed and space specifications are a critical part.
+ When: schedule
+ How much: budget
+ Where: space allocation
+ Who: organization chart.
** Why Have Formal Documents?
First, writing the decisions down is essential. 
The act
of writing turns out to require hundreds of mini-decisions, and it
is the existence of these that distinguishes clear, exact policies
from fuzzy ones.

Second, the documents will communicate the decisions to others.

Finally, a manager's documents give him a data base and
checklist. 

* Plan to Throw One Away
** Pilot Plants and Scaling Up
Hence plan to throw one away; you will, anyhow.
** The Only Constancy Is Change Itself
Nevertheless, some changes in objectives are inevitable, and it
is better to be prepared for them than to assume that they won't
come. Not only are changes in objective inevitable, changes in
development strategy and technique are also inevitable. The
throw-one-away concept is itself just an acceptance of the fact
that as one learns, he changes the design.[fn:9]
** Plan the System for Change
Quantization of change is an essential technique. Every prod-
uct should have numbered versions, and each version must have
its own schedule and a freeze date, after which changes go into the
next version.
** Plan the Organization for Change
Cosgrove advocates treating all plans, milestones, and schedules as
tentative, so as to facilitate change. This goes much too far—the
common failing of programming groups today is too little manage-
ment control, not too much.

Structuring an organization for change is much harder than
designing a system for change. Each man must be assigned to jobs
that broaden him, so that the whole force is technically flexible.
** One Step Forward and One Step Back
They find that the total number of
modules increases linearly with release number, but that the num-
ber of modules affected increases exponentially with release num-
ber. All repairs tend to destroy the structure, to increase the
entropy and disorder of the system. Less and less effort is spent
on fixing original design flaws; more and more is spent on fixing
flaws introduced by earlier fixes. As time passes, the system
becomes less and less well-ordered. Sooner or later the fixing
ceases to gain any ground. Each forward step is matched by a
backward one.
* Sharp Tools
Both specialized needs and personal preferences dictate the need for special-
ized tools as well; so in discussing programming teams I have
postulated one toolmaker per team. This man masters all the com-
mon tools and is able to instruct his client-boss in their use. He
also builds the specialized tools his boss needs.

What are the tools about which the manager must philoso-
phize, plan, and organize? First, a computer facility. This requires
machines, and a scheduling philosophy must be adopted. It requires an operating system, and service philosophies must be estab-
lished. It requires language, and a language policy must be laid
down. Then there are utilities, -debugging aids, test-case generators,
and a text-processing system to handle documentation. Let us look
at these one by one.[fn:10]
** Target Machines
Machine support is usefully divided into the target machine and the
vehicle machines. 
** Scheduling.
System debugging has always been a graveyard-shift occupation,
like astronomy. 
** Vehicle Machines and Data Services
Simulators. If the target computer is new, one needs a logical
simulator for it. This gives a debugging vehicle long before the real
target exists. Equally important, it gives access to a dependable
debugging vehicle even after one has a target machine available.

 So a dependable
simulator on a well-aged vehicle retains its usefulness far longer
than one would expect.

** Compiler and assembler vehicles. 
For the same reasons, one
wants compilers and assemblers that run on dependable vehicles
but compile object code for the target system. This can then start
being debugged on the simulator.

** Program libraries and accounting. 
First, each group or programmer had an area where he kept
copies of his programs, his test cases, and the scaffolding he
needed for component testing. In this playpen area there were no
restrictions on what a man could do with his own programs; they
were his.

Two notions are important here. The first is control, the idea
of program copies belonging to managers who alone can authorize
their change. The"second is that of formal separation and progression
from the playpen, to integration, to release.

** Program tools.
** Documentation system. 
Among all tools, the one that saves the
most labor may well be a computerized text-editing system, oper-
ating on a dependable vehicle.

** Performance simulator. 
Better have one. Build it outside-in. Start it very early. Listen to it when it speaks.
** High-Level Language and Interactive Programming
+ High-level language. The chief reasons for using a high-level
  language are productivity and debugging speed.

+ Interactive programming. There is a widespread recognition that
  debugging is the hard and slow part of system programming, and slow
  turnaround is the bane of debugging. So the logic of interactive
  programming seems inexorable.

* The Whole and the Parts
** Designing the Bugs Out
















* Footnotes

[fn:1] Backus, J. W., "The syntax and semantics of the proposed
international algebraic language." Proc, Intl. Con/. Inf. Proc.
UNESCO, Paris, 1959, published by R. Oldenbourg, Munich,
and Butterworth, London. Besides this, a whole collection
of papers on the subject is contained in T. B. Steel,
Jr. (ed.), Formal Language Description Languages for Computer
Programming. Amsterdam: North Holland, (1966).

[fn:2] Backus, J. W., "The syntax and semantics of the proposed
international algebraic language." Proc, Intl. Con/. Inf. Proc.
UNESCO, Paris, 1959, published by R. Oldenbourg, Munich,
and Butterworth, London. Besides this, a whole collection
of papers on the subject is contained in T. B. Steel,
Jr. (ed.), Formal Language Description Languages for Computer
Programming. Amsterdam: North Holland, (1966).

[fn:3] Iverson, K. E., A Programming Language. New York: Wiley,
1962, Chapter 2.

[fn:4] Iverson, K. E., A Programming Language. New York: Wiley,
1962, Chapter 2.

[fn:5] Bell and Newell have proposed new notations for describing
both configurations and machine architectures, and they have il-
lustrated these with several machines, including the DEC PDP-8,6
the 7090,6 and System/360.7

[fn:6] Bell, C. G., private communication.

[fn:7] Nanus, B., and L. Farr, "Some cost contributors to largescale
programs," AFIPS Proc. SJCC, 25 (Spring, 1964), pp.
239-248. 

[fn:8] Morin, L. H., "Estimation of resources for computer programming
projects," M. S. thesis, Univ. of North Carolina,
Chapel Hill, 1974.

[fn:9] The matter of design change is complex, and I oversimplify
here. See J. H. Saltzer, "Evolutionary design of complex systems,"
in D. Eckman (ed.), Systems: Research and Design.
New York: Wiley, 1961. When all is said and done, however,
I still advocate building a pilot system whose discarding is
planned.

[fn:10] See also J. W. Pomeroy, "A guide to programming tools and
techniques," IBM Sys. J., 11, 3 (1972), pp. 234-254.








